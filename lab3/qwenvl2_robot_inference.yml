nodes:
  - id: key-listener
    path: ../src/key_listener.py
    inputs:
      tick: dora/timer/millis/10
    outputs:
      - char

  - id: key-text
    path: ../src/key_text.py
    inputs:
      keyboard: key-listener/char
    outputs:
      - text

  - id: camera1
    _unstable_deploy:
      machine: pi
    path: opencv-video-capture
    inputs:
      tick: dora/timer/millis/200
    outputs:
      - image
    env:
      CAPTURE_PATH: 2
      IMAGE_WIDTH: 640
      IMAGE_HEIGHT: 480
      ENCODING: jpeg
      FLIP: BOTH

  - id: camera2
    _unstable_deploy:
      machine: pi
    path: opencv-video-capture
    inputs:
      tick: dora/timer/millis/200
    outputs:
      - image
    env:
      CAPTURE_PATH: 0
      IMAGE_WIDTH: 640
      IMAGE_HEIGHT: 480
      ENCODING: jpeg
      FLIP: BOTH

  - id: dora-qwenvl
    path: ../src/dora_qwenvl.py
    inputs:
      image_1:
        source: camera1/image
        queue_size: 1
      image_2:
        source: camera2/image
        queue_size: 1
      tick: dora/timer/millis/4000
#      text:  # 暂时不用，用来输入问题的
    outputs:
      - tick
#      - text # # 暂时不用，用来输出回答的
    env:
#      DEFAULT_QUESTION: Control the arm and claw by responding with commands such as “arm forward,” “arm backward,” “arm left,” “arm right,” “arm up,” “arm down,” “claw open,” and “claw close” to grab the bottle and place it into the blue tray. If the claw is empty, first use it to grab the bottle. Once you confirm the bottle is in the claw, move it to the blue tray. After confirming the bottle is in the tray, open the claw. Only respond with one command at a time.
      DEFAULT_QUESTION: Control the arm by responding with commands such as “arm left”, “arm right”, “claw open” and “claw close” to grab the bottle and place it into the blue box. If the claw is empty, first use it to grab the bottle. Once you confirm the bottle is in the claw, move it to the blue box. After confirming the bottle is in the tray, open the claw. Only respond with one command at a time.
#      DEFAULT_QUESTION: Control the arm by responding with commands such as “arm left”, “arm right”, "nothing". If you see red square turn arm right, or yellow square turn arm left. If you haven't seen the square with the color I mentioned, do nothing.
      USE_MODELSCOPE_HUB: True
      MODEL_NAME_OR_PATH: E:\Repositories\Qwen2-VL-7B-Instruct-GPTQ-Int4
      ADAPTER_PATH: E:\Work\LLaMA-Factory\my-qwen2_vl-7b-int4\lora\sft

  - id: plot
    path: dora-rerun
    inputs:
      image_1:
        source: camera1/image
        queue_size: 1
      image_2:
        source: camera2/image
        queue_size: 1
      textlog_vlm: dora-qwenvl/tick
    env:
      IMAGE_WIDTH: 640
      IMAGE_HEIGHT: 480
      RERUN_MEMORY_LIMIT: 50%
      README: |
        To control the robot, use the following keys:
        - w: move chassis forward
        - s: move chassis backward
        - a: move chassis left
        - d: move chassis right
        - q: close gripper
        - e: open gripper
        - t: move arm forward
        - g: move arm backward
        - f: move arm left
        - h: move arm right
        - r: move arm up
        - y: move arm down
        - x: save
        - c: clear
        - b: begin
        - n: stop
        - m: goto

  - id: trans-cmd
    path: ../src/trans_cmd.py
    inputs:
      key-qwenvl: dora-qwenvl/tick
      key-keyboard: key-text/text
    outputs:
      - movec
      - claw
      - save
      - clear
      - begin
      - stop
      - goto

  - id: arm
    path: ./src/gen72.py
    _unstable_deploy:
      machine: pi
    inputs:
      movec: trans-cmd/movec
      claw: trans-cmd/claw
      save: trans-cmd/save
      clear: trans-cmd/clear
      begin: trans-cmd/begin
      stop: trans-cmd/stop
      goto: trans-cmd/goto
    env:
      ROBOT_IP: 192.168.1.18


#  - id: chassis
#    path: robot
#    _unstable_deploy:
#      machine: pi
#    inputs:
#      text: dora-qwenvl/tick
